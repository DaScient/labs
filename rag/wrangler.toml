name = "rag-ubiq"
main = "worker.js"
compatibility_date = "2024-11-20"
workers_dev = true

account_id = "22202ff07e559347483b0526ded1fd31"

[ai]
binding = "AI"

[vars]
# RAG behavior defaults (override at runtime if you want)
RAG_TOP_K = "6"
RAG_MAX_CONTEXT_CHARS = "12000"
RAG_CHUNK_SIZE = "1600"        # chars
RAG_CHUNK_OVERLAP = "220"      # chars
RAG_SYSTEM_PROMPT = """You are a precise Retrieval-Augmented AI assistant. 
Use only the provided context to answer. If the answer is not in the context, say you don't know.
Cite sources as [S#] with their titles or filenames. Keep answers concise and correct."""

# Choose Cloudflare Workers AI models (stable, widely available)
EMBEDDING_MODEL = "@cf/baai/bge-small-en-v1.5"
GENERATION_MODEL = "@cf/meta/llama-3.1-8b-instruct"

# Optional: enable simple CORS for the static HTML UI when served elsewhere
CORS_ALLOW_ORIGIN = "*"

[[vectorize]]
binding = "VDB"                 # Vectorize binding name in worker code
index_name = "rag-ubiq-index"   # Create this with `wrangler vectorize` (see below)

[[r2_buckets]]
binding = "DOCS"                # R2 bucket for raw docs/chunks
bucket_name = "rag-ubiq-docs"

[[kv_namespaces]]
binding = "DOC_META"
id = "6806f0b27b60448bbe8ac9f3bba2a4e8"

[[kv_namespaces]]
binding = "RAG_KV"
id = "721d959b75ab4bed88d0153cf1408d64"